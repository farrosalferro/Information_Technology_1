{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac514875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farrosalferro/miniconda3/envs/kaggle/lib/python3.10/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/home/farrosalferro/miniconda3/envs/kaggle/lib/python3.10/site-packages/lightglue/lightglue.py:24: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "/home/farrosalferro/miniconda3/envs/kaggle/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm # Progress bars\n",
    "import gc # Garbage collection for memory management\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "\n",
    "# Import individual modules to avoid circular imports\n",
    "from scripts.utils import dataset, camera, image, metric, submission\n",
    "from scripts.features import extraction, clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7018838c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constants defined. Using SIFT features and FLANN matcher.\n",
      "Data Directory: ../data/image-matching-challenge-2025\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../data/image-matching-challenge-2025\"\n",
    "OUTPUT_FILE = \"output_graph.csv\" # Output file for results\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "\n",
    "\n",
    "# --- Feature Extraction Parameters ---\n",
    "# Options: 'SIFT', 'AKAZE', 'ORB' (DISK/ALIKED need external setup)\n",
    "FEATURE_EXTRACTOR_TYPE = 'SIFT'\n",
    "SIFT_NFEATURES = 8000 # Max features per image for SIFT\n",
    "\n",
    "# --- Matching Parameters ---\n",
    "MATCHER_TYPE = 'FLANN' # 'BF' (Brute Force) or 'FLANN' (Fast Library for Approximate Nearest Neighbors)\n",
    "LOWE_RATIO_TEST_THRESHOLD = 0.8 # For filtering good matches (knnMatch ratio)\n",
    "MIN_INLIER_MATCHES_INITIAL = 15 # Min inliers for initial pairwise geometry check\n",
    "MIN_INLIER_MATCHES_GRAPH = 10 # Min inliers to add edge to view graph (can be lower)\n",
    "\n",
    "# --- Geometric Verification (RANSAC for Fundamental Matrix) ---\n",
    "RANSAC_THRESHOLD = 1.5 # RANSAC reprojection threshold in pixels for findFundamentalMat\n",
    "\n",
    "# --- Clustering Parameters ---\n",
    "# Options: 'ConnectedComponents', 'Spectral'\n",
    "CLUSTERING_ALGORITHM = 'ConnectedComponents'\n",
    "MIN_CLUSTER_SIZE = 3 # Minimum images to form a valid scene cluster\n",
    "\n",
    "# --- SfM Parameters ---\n",
    "MIN_VIEWS_FOR_TRIANGULATION = 2 # Need at least two views for triangulation\n",
    "PNP_RANSAC_THRESHOLD = 5.0 # RANSAC reprojection threshold for solvePnPRansac\n",
    "PNP_CONFIDENCE = 0.999 # Confidence for PnPRansac\n",
    "MIN_3D_POINTS_FOR_PNP = 6 # Minimum 3D points required for PnP\n",
    "\n",
    "# --- Camera Intrinsics (Approximation - Not submitted, but needed for E/PnP) ---\n",
    "# We estimate a default K matrix. Real K varies per image, but this is a common\n",
    "# simplification if intrinsics aren't provided or estimated.\n",
    "# Focal length is often approximated based on image width.\n",
    "DEFAULT_FOCAL_LENGTH_FACTOR = 1.2\n",
    "# Assuming cx, cy are image center. Will be calculated per image later.\n",
    "\n",
    "print(f\"Constants defined. Using {FEATURE_EXTRACTOR_TYPE} features and {MATCHER_TYPE} matcher.\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f49fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"imc2023_haiper\" -> num_images=54\n",
      "Dataset \"imc2023_heritage\" -> num_images=209\n",
      "Dataset \"imc2023_theather_imc2024_church\" -> num_images=76\n",
      "Dataset \"imc2024_dioscuri_baalshamin\" -> num_images=138\n",
      "Dataset \"imc2024_lizard_pond\" -> num_images=214\n",
      "Dataset \"pt_brandenburg_british_buckingham\" -> num_images=225\n",
      "Dataset \"pt_piazzasanmarco_grandplace\" -> num_images=168\n",
      "Dataset \"pt_sacrecoeur_trevi_tajmahal\" -> num_images=225\n",
      "Dataset \"pt_stpeters_stpauls\" -> num_images=200\n",
      "Dataset \"amy_gardens\" -> num_images=200\n",
      "Dataset \"fbk_vineyard\" -> num_images=163\n",
      "Dataset \"ETs\" -> num_images=22\n",
      "Dataset \"stairs\" -> num_images=51\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "samples = dataset.load_dataset(DATA_DIR)\n",
    "\n",
    "for dataset_name in samples:\n",
    "    print(f'Dataset \"{dataset_name}\" -> num_images={len(samples[dataset_name])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a411ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matcher here to avoid circular import issues\n",
    "from scripts.features import matching\n",
    "\n",
    "def process_dataset(dataset_id, test_image_dir, predictions, extractor, matcher):\n",
    "    \"\"\"Runs the full pipeline for a single dataset.\"\"\"\n",
    "    print(f\"\\n--- Processing Dataset: {dataset_id} ---\")\n",
    "\n",
    "    dataset_path = os.path.join(test_image_dir, dataset_id)\n",
    "    filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "    # 1. Extract Features\n",
    "    extracted_features, image_dims = extraction.load_and_extract_features_dataset(dataset_id, test_image_dir, extractor)\n",
    "    image_ids_in_dataset = list(extracted_features.keys())\n",
    "\n",
    "    if not extracted_features:\n",
    "        print(f\"No extracted_features extracted for dataset {dataset_id}. Marking all as outliers.\")\n",
    "        # Use image list from directory listing if extracted_features is empty but dir exists\n",
    "        all_images = list(f.name for f in dataset_path.glob('*.png')) + \\\n",
    "                    list(f.name for f in dataset_path.glob('*.jpg')) + \\\n",
    "                    list(f.name for f in dataset_path.glob('*.jpeg'))\n",
    "        for img_id in all_images:\n",
    "            r_str, t_str = camera.format_pose(None, None)\n",
    "            prediction_index = filename_to_index[img_id]\n",
    "            predictions[prediction_index].cluster_index = \"outliers\"\n",
    "            predictions[prediction_index].rotation = deepcopy(r_str)\n",
    "            predictions[prediction_index].translation = deepcopy(t_str)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    # Add images found in directory but failed extraction to image_ids_in_dataset\n",
    "    all_images_found = list(image_dims.keys())\n",
    "    image_ids_set = set(image_ids_in_dataset)\n",
    "    for img_id in all_images_found:\n",
    "        if img_id not in image_ids_set:\n",
    "            image_ids_in_dataset.append(img_id)\n",
    "\n",
    "\n",
    "    # 2. Build View Graph\n",
    "    G, pairwise_matches = clustering.build_view_graph(image_ids_in_dataset, extracted_features, matcher)\n",
    "\n",
    "\n",
    "    # 3. Cluster Images\n",
    "    clusters, outliers = clustering.cluster_images(G, algorithm=CLUSTERING_ALGORITHM, min_cluster_size=MIN_CLUSTER_SIZE)\n",
    "\n",
    "    # 4. Process Outliers\n",
    "    print(f\"Marking {len(outliers)} images as outliers.\")\n",
    "    for img_id in outliers:\n",
    "        r, t = camera.format_pose(None, None)\n",
    "        prediction_index = filename_to_index[img_id]\n",
    "        predictions[prediction_index].cluster_index = \"outliers\"\n",
    "        predictions[prediction_index].rotation = r\n",
    "        predictions[prediction_index].translation = t\n",
    "\n",
    "    # 5. Run SfM per Cluster\n",
    "    print(f\"Running SfM for {len(clusters)} clusters...\")\n",
    "    for i, cluster_nodes in enumerate(clusters):\n",
    "        cluster_label = f\"cluster{i+1}\"\n",
    "        print(f\"\\nProcessing {cluster_label} ({len(cluster_nodes)} images)...\")\n",
    "\n",
    "        # Filter extracted_features/dims/matches for the current cluster\n",
    "        cluster_features = {img_id: extracted_features[img_id] for img_id in cluster_nodes if img_id in extracted_features}\n",
    "        cluster_dims = {img_id: image_dims[img_id] for img_id in cluster_nodes if img_id in image_dims}\n",
    "        # Filter pairwise matches (tricky, need both nodes in cluster)\n",
    "        cluster_pairwise_matches = {}\n",
    "        for (id1, id2), matches in pairwise_matches.items():\n",
    "             if id1 in cluster_nodes and id2 in cluster_nodes:\n",
    "                 cluster_pairwise_matches[(id1, id2)] = matches\n",
    "\n",
    "\n",
    "        cluster_poses = camera.estimate_poses_for_cluster(\n",
    "            cluster_nodes,\n",
    "            cluster_features,\n",
    "            cluster_dims,\n",
    "            matcher,\n",
    "            cluster_pairwise_matches # Pass filtered matches\n",
    "        )\n",
    "\n",
    "        # Add results for this cluster\n",
    "        for img_id in cluster_nodes:\n",
    "            R, T = cluster_poses.get(img_id, (None, None)) # Get pose, default to None if not found\n",
    "            r, t = camera.format_pose(R, T)\n",
    "            prediction_index = filename_to_index[img_id]\n",
    "            predictions[prediction_index].cluster_index = cluster_label\n",
    "            predictions[prediction_index].rotation = deepcopy(r)\n",
    "            predictions[prediction_index].translation = deepcopy(t)\n",
    "\n",
    "        # Clean up memory\n",
    "        del cluster_features, cluster_dims, cluster_poses, cluster_pairwise_matches\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"--- Finished Processing Dataset: {dataset_id} ---\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59070e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Train Datasets ===\n",
      "\n",
      "--- Processing Dataset: ETs ---\n",
      "Extracting features for 22 images in dataset ETs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features ETs: 100%|██████████| 22/22 [00:00<00:00, 41.05it/s]\n",
      "Features ETs: 100%|██████████| 22/22 [00:00<00:00, 41.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building view graph for 22 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching pairs: 100%|██████████| 231/231 [00:04<00:00, 52.34it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View graph built with 22 nodes and 62 edges.\n",
      "Clustering graph using ConnectedComponents...\n",
      "Found 1 clusters and 2 potential outliers.\n",
      "Marking 2 images as outliers.\n",
      "Running SfM for 1 clusters...\n",
      "\n",
      "Processing cluster1 (20 images)...\n",
      "Initializing SfM with pair (another_et_another_et002.png, another_et_another_et001.png) with 503 matches.\n",
      "Essential matrix inliers: 467\n",
      "Triangulated 455 initial 3D points.\n",
      "Attempting to register 18 remaining images...\n",
      "Initializing SfM with pair (another_et_another_et002.png, another_et_another_et001.png) with 503 matches.\n",
      "Essential matrix inliers: 467\n",
      "Triangulated 455 initial 3D points.\n",
      "Attempting to register 18 remaining images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering images: 100%|██████████| 18/18 [00:00<00:00, 1592.77it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully registered image another_et_another_et005.png (109 PnP inliers).\n",
      "Successfully registered image another_et_another_et004.png (107 PnP inliers).\n",
      "Successfully registered image another_et_another_et003.png (56 PnP inliers).\n",
      "Successfully registered image another_et_another_et006.png (36 PnP inliers).\n",
      "Successfully registered image another_et_another_et007.png (14 PnP inliers).\n",
      "Finished SfM for cluster. Registered 7 out of 20 images.\n",
      "--- Finished Processing Dataset: ETs ---\n",
      "\n",
      "--- Processing Dataset: stairs ---\n",
      "Extracting features for 51 images in dataset stairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features stairs: 100%|██████████| 51/51 [00:06<00:00,  8.35it/s]\n",
      "Features stairs: 100%|██████████| 51/51 [00:06<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building view graph for 51 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching pairs: 100%|██████████| 1275/1275 [00:13<00:00, 92.12it/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View graph built with 51 nodes and 212 edges.\n",
      "Clustering graph using ConnectedComponents...\n",
      "Found 1 clusters and 2 potential outliers.\n",
      "Marking 2 images as outliers.\n",
      "Running SfM for 1 clusters...\n",
      "\n",
      "Processing cluster1 (49 images)...\n",
      "Initializing SfM with pair (stairs_split_1_1710453576271.png, stairs_split_1_1710453955270.png) with 37 matches.\n",
      "Essential matrix inliers: 34\n",
      "Triangulated 20 initial 3D points.\n",
      "Attempting to register 47 remaining images...\n",
      "Initializing SfM with pair (stairs_split_1_1710453576271.png, stairs_split_1_1710453955270.png) with 37 matches.\n",
      "Essential matrix inliers: 34\n",
      "Triangulated 20 initial 3D points.\n",
      "Attempting to register 47 remaining images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering images: 100%|██████████| 47/47 [00:00<00:00, 66063.10it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully registered image stairs_split_2_1710453783374.png (7 PnP inliers).\n",
      "Finished SfM for cluster. Registered 3 out of 49 images.\n",
      "--- Finished Processing Dataset: stairs ---\n",
      "\n",
      "--- Processing Dataset: imc2023_haiper ---\n",
      "Extracting features for 54 images in dataset imc2023_haiper...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features imc2023_haiper: 100%|██████████| 54/54 [00:14<00:00,  3.64it/s]\n",
      "Features imc2023_haiper: 100%|██████████| 54/54 [00:14<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building view graph for 54 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching pairs: 100%|██████████| 1431/1431 [02:51<00:00,  8.34it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View graph built with 54 nodes and 412 edges.\n",
      "Clustering graph using ConnectedComponents...\n",
      "Found 1 clusters and 0 potential outliers.\n",
      "Marking 0 images as outliers.\n",
      "Running SfM for 1 clusters...\n",
      "\n",
      "Processing cluster1 (54 images)...\n",
      "Initializing SfM with pair (fountain_image_136.png, fountain_image_082.png) with 896 matches.\n",
      "Essential matrix inliers: 634\n",
      "Triangulated 634 initial 3D points.\n",
      "Attempting to register 52 remaining images...\n",
      "Initializing SfM with pair (fountain_image_136.png, fountain_image_082.png) with 896 matches.\n",
      "Essential matrix inliers: 634\n",
      "Triangulated 634 initial 3D points.\n",
      "Attempting to register 52 remaining images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering images: 100%|██████████| 52/52 [00:00<00:00, 932.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully registered image fountain_image_129.png (101 PnP inliers).\n",
      "Successfully registered image fountain_image_000.png (44 PnP inliers).\n",
      "Successfully registered image fountain_image_143.png (19 PnP inliers).\n",
      "Successfully registered image fountain_image_071.png (35 PnP inliers).\n",
      "Successfully registered image fountain_image_007.png (10 PnP inliers).\n",
      "Successfully registered image fountain_image_012.png (7 PnP inliers).\n",
      "Successfully registered image fountain_image_214.png (37 PnP inliers).\n",
      "Successfully registered image fountain_image_056.png (12 PnP inliers).\n",
      "Successfully registered image fountain_image_230.png (27 PnP inliers).\n",
      "Successfully registered image fountain_image_041.png (12 PnP inliers).\n",
      "Successfully registered image fountain_image_025.png (15 PnP inliers).\n",
      "Successfully registered image fountain_image_101.png (8 PnP inliers).\n",
      "Successfully registered image fountain_image_199.png (19 PnP inliers).\n",
      "Successfully registered image fountain_image_116.png (18 PnP inliers).\n",
      "Successfully registered image fountain_image_033.png (16 PnP inliers).\n",
      "Successfully registered image fountain_image_173.png (10 PnP inliers).\n",
      "Successfully registered image fountain_image_186.png (8 PnP inliers).\n",
      "Successfully registered image fountain_image_155.png (13 PnP inliers).\n",
      "Finished SfM for cluster. Registered 20 out of 54 images.\n",
      "--- Finished Processing Dataset: imc2023_haiper ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process train datasets\n",
    "if os.path.isdir(TRAIN_DIR):\n",
    "    train_datasets = [os.path.basename(os.path.join(TRAIN_DIR, d)) for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))]\n",
    "    # sort train datasets based on their number of files\n",
    "    train_datasets.sort(key=lambda x: len(os.listdir(os.path.join(TRAIN_DIR, x))), reverse=False)\n",
    "    print(\"=== Processing Train Datasets ===\")\n",
    "    extractor = extraction.get_feature_extractor('SIFT', SIFT_NFEATURES)\n",
    "    matcher = matching.get_matcher('FLANN', 'SIFT')\n",
    "    for dataset_name in train_datasets[:3]:\n",
    "        samples[dataset_name] = process_dataset(dataset_name, TRAIN_DIR, samples[dataset_name], extractor, matcher)\n",
    "else:\n",
    "    print(\"Train directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2fa9016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset,scene,image,rotation_matrix,translation_vector\n",
      "imc2023_haiper,clustercluster1,fountain_image_116.png,-0.904877030;-0.332588306;0.265673821;0.414172203;-0.543800618;0.729891960;-0.098279943;0.770497181;0.629821520,-0.386007028;-0.757245401;0.001618247\n",
      "imc2023_haiper,clustercluster1,fountain_image_108.png,nan;nan;nan;nan;nan;nan;nan;nan;nan,nan;nan;nan\n",
      "imc2023_haiper,clustercluster1,fountain_image_101.png,-0.424429027;0.859171113;-0.285805877;-0.806752358;-0.215513193;0.550186057;0.411109030;0.464089498;0.784608376,0.351741140;-0.678798907;-0.088142393\n",
      "imc2023_haiper,clustercluster1,fountain_image_082.png,0.958820137;-0.200502699;0.201153209;0.020377353;0.754991023;0.655418431;-0.283282031;-0.624329419;0.727986310,-0.309231126;-0.839983378;0.445874461\n",
      "imc2023_haiper,clustercluster1,fountain_image_071.png,0.332224305;-0.888808539;0.315668168;0.322766725;0.421604113;0.847391063;-0.886255410;-0.179636726;0.426944955,-0.368747138;-1.184375493;0.748708858\n",
      "imc2023_haiper,clustercluster1,fountain_image_025.png,-0.100752373;0.929065867;0.355929170;-0.959538310;-0.185285482;0.212027173;0.262935717;-0.320165433;0.910142244,-1.023340232;0.177496782;-0.232156482\n",
      "imc2023_haiper,clustercluster1,fountain_image_000.png,0.934212981;0.303698813;0.187117976;-0.347884533;0.659676277;0.666185830;0.078882556;-0.687454900;0.721930261,-0.471152397;-0.910430781;0.748996288\n",
      "imc2023_haiper,clustercluster1,fountain_image_007.png,0.487632166;0.860347120;-0.148383636;-0.522249028;0.423651021;0.740118751;0.699621915;-0.283412500;0.655901312,-0.052552162;-1.114389532;0.511890073\n",
      "imc2023_haiper,clustercluster1,fountain_image_012.png,0.395837014;0.897197248;0.195831962;-0.599132498;0.090699430;0.795495986;0.695954962;-0.432216048;0.573442219,-0.552751781;-1.195002273;0.110065882\n"
     ]
    }
   ],
   "source": [
    "# Create a submission file.\n",
    "submission.create_submission_file(samples, OUTPUT_FILE)\n",
    "\n",
    "!head {OUTPUT_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6e2753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imc2023_haiper: score=0.00% (mAA=0.00%, clusterness=33.33%)\n",
      "imc2023_heritage: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "imc2023_theather_imc2024_church: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "imc2024_dioscuri_baalshamin: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "imc2024_lizard_pond: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "pt_brandenburg_british_buckingham: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "pt_piazzasanmarco_grandplace: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "pt_sacrecoeur_trevi_tajmahal: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "pt_stpeters_stpauls: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "amy_gardens: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "fbk_vineyard: score=0.00% (mAA=0.00%, clusterness=0.00%)\n",
      "ETs: score=0.00% (mAA=0.00%, clusterness=47.50%)\n",
      "stairs: score=0.00% (mAA=0.00%, clusterness=50.00%)\n",
      "Average over all datasets: score=0.00% (mAA=0.00%, clusterness=10.06%)\n"
     ]
    }
   ],
   "source": [
    "# Compute results if running on the training set.\n",
    "# Don't do this when submitting a notebook for scoring. All you have to do is save your submission to /kaggle/working/submission.csv.\n",
    "\n",
    "final_score, dataset_scores = metric.score(\n",
    "    gt_csv=os.path.join(DATA_DIR, \"train_labels.csv\"),\n",
    "    user_csv=OUTPUT_FILE,\n",
    "    thresholds_csv=os.path.join(DATA_DIR, \"train_thresholds.csv\"),\n",
    "    mask_csv=None,\n",
    "    inl_cf=0,\n",
    "    strict_cf=-1,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
