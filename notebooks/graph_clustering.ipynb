{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac514875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm # Progress bars\n",
    "import gc # Garbage collection for memory management\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "\n",
    "# Import individual modules to avoid circular imports\n",
    "from scripts.utils import dataset, camera, image, metric, submission\n",
    "from scripts.features import extraction, clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/image-matching-challenge-2025\"\n",
    "OUTPUT_FILE = \"output_graph.csv\" # Output file for results\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "\n",
    "\n",
    "# --- Feature Extraction Parameters ---\n",
    "# Options: 'SIFT', 'AKAZE', 'ORB' (DISK/ALIKED need external setup)\n",
    "FEATURE_EXTRACTOR_TYPE = 'SIFT'\n",
    "SIFT_NFEATURES = 8000 # Max features per image for SIFT\n",
    "\n",
    "# --- Matching Parameters ---\n",
    "MATCHER_TYPE = 'FLANN' # 'BF' (Brute Force) or 'FLANN' (Fast Library for Approximate Nearest Neighbors)\n",
    "LOWE_RATIO_TEST_THRESHOLD = 0.8 # For filtering good matches (knnMatch ratio)\n",
    "MIN_INLIER_MATCHES_INITIAL = 15 # Min inliers for initial pairwise geometry check\n",
    "MIN_INLIER_MATCHES_GRAPH = 10 # Min inliers to add edge to view graph (can be lower)\n",
    "\n",
    "# --- Geometric Verification (RANSAC for Fundamental Matrix) ---\n",
    "RANSAC_THRESHOLD = 1.5 # RANSAC reprojection threshold in pixels for findFundamentalMat\n",
    "\n",
    "# --- Clustering Parameters ---\n",
    "# Options: 'ConnectedComponents', 'Spectral'\n",
    "CLUSTERING_ALGORITHM = 'ConnectedComponents'\n",
    "MIN_CLUSTER_SIZE = 3 # Minimum images to form a valid scene cluster\n",
    "\n",
    "# --- SfM Parameters ---\n",
    "MIN_VIEWS_FOR_TRIANGULATION = 2 # Need at least two views for triangulation\n",
    "PNP_RANSAC_THRESHOLD = 5.0 # RANSAC reprojection threshold for solvePnPRansac\n",
    "PNP_CONFIDENCE = 0.999 # Confidence for PnPRansac\n",
    "MIN_3D_POINTS_FOR_PNP = 6 # Minimum 3D points required for PnP\n",
    "\n",
    "# --- Camera Intrinsics (Approximation - Not submitted, but needed for E/PnP) ---\n",
    "# We estimate a default K matrix. Real K varies per image, but this is a common\n",
    "# simplification if intrinsics aren't provided or estimated.\n",
    "# Focal length is often approximated based on image width.\n",
    "DEFAULT_FOCAL_LENGTH_FACTOR = 1.2\n",
    "# Assuming cx, cy are image center. Will be calculated per image later.\n",
    "\n",
    "print(f\"Constants defined. Using {FEATURE_EXTRACTOR_TYPE} features and {MATCHER_TYPE} matcher.\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f49fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "samples = dataset.load_dataset(DATA_DIR)\n",
    "\n",
    "for dataset_name in samples:\n",
    "    print(f'Dataset \"{dataset_name}\" -> num_images={len(samples[dataset_name])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a411ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matcher here to avoid circular import issues\n",
    "from scripts.features import matching\n",
    "\n",
    "def process_dataset(dataset_id, test_image_dir, predictions, extractor, matcher):\n",
    "    \"\"\"Runs the full pipeline for a single dataset.\"\"\"\n",
    "    print(f\"\\n--- Processing Dataset: {dataset_id} ---\")\n",
    "\n",
    "    dataset_path = os.path.join(test_image_dir, dataset_id)\n",
    "    filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "    # 1. Extract Features\n",
    "    extracted_features, image_dims = extraction.load_and_extract_features_dataset(dataset_id, test_image_dir, extractor)\n",
    "    image_ids_in_dataset = list(extracted_features.keys())\n",
    "\n",
    "    if not extracted_features:\n",
    "        print(f\"No extracted_features extracted for dataset {dataset_id}. Marking all as outliers.\")\n",
    "        # Use image list from directory listing if extracted_features is empty but dir exists\n",
    "        all_images = list(f.name for f in dataset_path.glob('*.png')) + \\\n",
    "                    list(f.name for f in dataset_path.glob('*.jpg')) + \\\n",
    "                    list(f.name for f in dataset_path.glob('*.jpeg'))\n",
    "        for img_id in all_images:\n",
    "            r_str, t_str = camera.format_pose(None, None)\n",
    "            prediction_index = filename_to_index[img_id]\n",
    "            predictions[prediction_index].cluster_index = \"outliers\"\n",
    "            predictions[prediction_index].rotation = deepcopy(r_str)\n",
    "            predictions[prediction_index].translation = deepcopy(t_str)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    # Add images found in directory but failed extraction to image_ids_in_dataset\n",
    "    all_images_found = list(image_dims.keys())\n",
    "    image_ids_set = set(image_ids_in_dataset)\n",
    "    for img_id in all_images_found:\n",
    "        if img_id not in image_ids_set:\n",
    "            image_ids_in_dataset.append(img_id)\n",
    "\n",
    "\n",
    "    # 2. Build View Graph\n",
    "    G, pairwise_matches = clustering.build_view_graph(image_ids_in_dataset, extracted_features, matcher)\n",
    "\n",
    "\n",
    "    # 3. Cluster Images\n",
    "    clusters, outliers = clustering.cluster_images(G, algorithm=CLUSTERING_ALGORITHM, min_cluster_size=MIN_CLUSTER_SIZE)\n",
    "\n",
    "    # 4. Process Outliers\n",
    "    print(f\"Marking {len(outliers)} images as outliers.\")\n",
    "    for img_id in outliers:\n",
    "        r, t = camera.format_pose(None, None)\n",
    "        prediction_index = filename_to_index[img_id]\n",
    "        predictions[prediction_index].cluster_index = \"outliers\"\n",
    "        predictions[prediction_index].rotation = r\n",
    "        predictions[prediction_index].translation = t\n",
    "\n",
    "    # 5. Run SfM per Cluster\n",
    "    print(f\"Running SfM for {len(clusters)} clusters...\")\n",
    "    for i, cluster_nodes in enumerate(clusters):\n",
    "        cluster_label = f\"cluster{i+1}\"\n",
    "        print(f\"\\nProcessing {cluster_label} ({len(cluster_nodes)} images)...\")\n",
    "\n",
    "        # Filter extracted_features/dims/matches for the current cluster\n",
    "        cluster_features = {img_id: extracted_features[img_id] for img_id in cluster_nodes if img_id in extracted_features}\n",
    "        cluster_dims = {img_id: image_dims[img_id] for img_id in cluster_nodes if img_id in image_dims}\n",
    "        # Filter pairwise matches (tricky, need both nodes in cluster)\n",
    "        cluster_pairwise_matches = {}\n",
    "        for (id1, id2), matches in pairwise_matches.items():\n",
    "             if id1 in cluster_nodes and id2 in cluster_nodes:\n",
    "                 cluster_pairwise_matches[(id1, id2)] = matches\n",
    "\n",
    "\n",
    "        cluster_poses = camera.estimate_poses_for_cluster(\n",
    "            cluster_nodes,\n",
    "            cluster_features,\n",
    "            cluster_dims,\n",
    "            matcher,\n",
    "            cluster_pairwise_matches # Pass filtered matches\n",
    "        )\n",
    "\n",
    "        # Add results for this cluster\n",
    "        for img_id in cluster_nodes:\n",
    "            R, T = cluster_poses.get(img_id, (None, None)) # Get pose, default to None if not found\n",
    "            r, t = camera.format_pose(R, T)\n",
    "            prediction_index = filename_to_index[img_id]\n",
    "            predictions[prediction_index].cluster_index = cluster_label\n",
    "            predictions[prediction_index].rotation = deepcopy(r)\n",
    "            predictions[prediction_index].translation = deepcopy(t)\n",
    "\n",
    "        # Clean up memory\n",
    "        del cluster_features, cluster_dims, cluster_poses, cluster_pairwise_matches\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"--- Finished Processing Dataset: {dataset_id} ---\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59070e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process train datasets\n",
    "if os.path.isdir(TRAIN_DIR):\n",
    "    train_datasets = [os.path.basename(os.path.join(TRAIN_DIR, d)) for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))]\n",
    "    # sort train datasets based on their number of files\n",
    "    train_datasets.sort(key=lambda x: len(os.listdir(os.path.join(TRAIN_DIR, x))), reverse=False)\n",
    "    print(\"=== Processing Train Datasets ===\")\n",
    "    extractor = extraction.get_feature_extractor('SIFT', SIFT_NFEATURES)\n",
    "    matcher = matching.get_matcher('FLANN', 'SIFT')\n",
    "    for dataset_name in train_datasets[:3]:\n",
    "        samples[dataset_name] = process_dataset(dataset_name, TRAIN_DIR, samples[dataset_name], extractor, matcher)\n",
    "else:\n",
    "    print(\"Train directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission file.\n",
    "submission.create_submission_file(samples, OUTPUT_FILE)\n",
    "\n",
    "!head {OUTPUT_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute results if running on the training set.\n",
    "# Don't do this when submitting a notebook for scoring. All you have to do is save your submission to /kaggle/working/submission.csv.\n",
    "\n",
    "final_score, dataset_scores = metric.score(\n",
    "    gt_csv=os.path.join(DATA_DIR, \"train_labels.csv\"),\n",
    "    user_csv=OUTPUT_FILE,\n",
    "    thresholds_csv=os.path.join(DATA_DIR, \"train_thresholds.csv\"),\n",
    "    mask_csv=None,\n",
    "    inl_cf=0,\n",
    "    strict_cf=-1,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
