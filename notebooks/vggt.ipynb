{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771eab85",
   "metadata": {},
   "source": [
    "## VGGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29763ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vggt.models.vggt import VGGT\n",
    "from vggt.utils.load_fn import load_and_preprocess_images\n",
    "from vggt.utils.pose_enc import pose_encoding_to_extri_intri\n",
    "from vggt.utils.geometry import unproject_depth_map_to_point_map\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "from scripts import utils, features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.metrics import silhouette_score\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5515c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/image-matching-challenge-2025\"\n",
    "VGGT_DIR = \"weights/vggt-1B\"\n",
    "OUTPUT_FILE = \"train_predictions.csv\"\n",
    "FEATURES_DIR = \"vggt_features/last_features\"\n",
    "# Configure dataset filtering \n",
    "DATASETS_FILTER = [\n",
    "    # New 2025 datasets\n",
    "    \"amy_gardens\",\n",
    "    \"ETs\",\n",
    "    \"fbk_vineyard\",\n",
    "    \"stairs\",\n",
    "    # Data from IMC 2023 and 2024.\n",
    "    'imc2024_dioscuri_baalshamin',\n",
    "    'imc2023_theather_imc2024_church',\n",
    "    'imc2023_heritage',\n",
    "    'imc2023_haiper',\n",
    "    'imc2024_lizard_pond',\n",
    "    # Crowdsourced PhotoTourism data.\n",
    "    'pt_stpeters_stpauls',\n",
    "    'pt_brandenburg_british_buckingham',\n",
    "    'pt_piazzasanmarco_grandplace',\n",
    "    'pt_sacrecoeur_trevi_tajmahal',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259056c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "samples = utils.dataset.load_dataset(DATA_DIR)\n",
    "\n",
    "for dataset in samples:\n",
    "    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e4084",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# bfloat16 is supported on Ampere GPUs (Compute Capability 8.0+) \n",
    "dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\n",
    "\n",
    "# Initialize the model and load the pretrained weights.\n",
    "model = VGGT.from_pretrained(VGGT_DIR).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17923b01",
   "metadata": {},
   "source": [
    "## Do Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_pooling(x):\n",
    "    return np.mean([image_feature[5:, :] for image_feature in x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory to prevent OOM errors\n",
    "gc.collect()\n",
    "mapping_result_strs = []  # Store results for each dataset\n",
    "\n",
    "print(f\"Extracting on device {device}\")\n",
    "# Process each dataset\n",
    "for dataset, predictions in samples.items():\n",
    "    # Skip datasets not in filter list\n",
    "    if DATASETS_FILTER and dataset not in DATASETS_FILTER:\n",
    "        print(f'Skipping \"{dataset}\"')\n",
    "        continue\n",
    "\n",
    "    # Setup paths and image lists\n",
    "    images_dir = os.path.join(DATA_DIR, \"train\", dataset)\n",
    "    images = sorted([os.path.join(images_dir, p.filename) for p in predictions])\n",
    "    features_dir = os.path.join(FEATURES_DIR, dataset)\n",
    "\n",
    "    # get all files with .pt extension\n",
    "    features_files = [f for f in os.listdir(features_dir) if f.endswith('.pt')]\n",
    "    vggt_features = []\n",
    "    for feature_file in features_files:\n",
    "        feature_path = os.path.join(features_dir, feature_file)\n",
    "        feature = torch.load(feature_path)[0]\n",
    "        if feature.shape[1] != 1374:\n",
    "            num_images, num_patches, num_channels = feature.shape\n",
    "            register_tokens = feature[:, :5, :]\n",
    "            patch_tokens = feature[:, 5:, :].reshape(num_images, -1, 37, num_channels).permute(0, 3, 1, 2)\n",
    "            patch_tokens_interpolated = torch.nn.functional.interpolate(\n",
    "                patch_tokens, size=(37, 37), mode='bilinear', align_corners=False\n",
    "            ).permute(0, 2, 3, 1).reshape(num_images, -1, num_channels)\n",
    "            feature = torch.cat((register_tokens, patch_tokens_interpolated), dim=1)\n",
    "            assert feature.shape[1] == 1374, f\"Feature shape mismatch: {feature.shape}\"\n",
    "        vggt_features.append(feature)\n",
    "    vggt_features = torch.cat(vggt_features, dim=0)\n",
    "\n",
    "    # Map filenames to prediction indices\n",
    "    filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "\n",
    "    try:\n",
    "        # cluster the features\n",
    "        reduced_features = features.extraction.feature_reducer(\n",
    "            algorithm=\"UMAP\",\n",
    "            features=np.vstack(patch_pooling(vggt_features.cpu().numpy())),\n",
    "            n_components=20,\n",
    "            random_state=42,\n",
    "        )\n",
    "        cluster_labels = features.clustering.dino_clusterer(\n",
    "                algorithm=\"HDBSCAN\",\n",
    "                features=reduced_features,\n",
    "                scaler=None,\n",
    "                min_cluster_size=2,\n",
    "        )\n",
    "        print(\n",
    "            f\"Clustering. Number of clusters: {np.unique(cluster_labels)}, with {sum(cluster_labels == -1)} outliers.\"\n",
    "        )\n",
    "        gc.collect()\n",
    "        vggt_features = vggt_features[cluster_labels != -1]\n",
    "        images_np = np.array(images)[cluster_labels != -1]\n",
    "        cluster_labels = cluster_labels[cluster_labels != -1]\n",
    "        for cluster in np.unique(cluster_labels):\n",
    "            vggt_features_cluster = vggt_features[cluster_labels == cluster]\n",
    "            cluster_images = images_np[cluster_labels == cluster]\n",
    "\n",
    "            print(f\"Processing Cluster {cluster}: {len(vggt_features_cluster)} images\")\n",
    "\n",
    "            pose_enc = model.camera_head([vggt_features_cluster.unsqueeze(0)])[-1]\n",
    "            translations = pose_enc[0, :, :3]\n",
    "            rotation_matrices = utils.camera.quat_to_cam_pose(pose_enc[0, :, 3:7])\n",
    "\n",
    "            for image_path, translation, rotation_matrix in zip(cluster_images, translations, rotation_matrices):\n",
    "                prediction_index = filename_to_index[os.path.basename(image_path)]\n",
    "                predictions[prediction_index].cluster_index = cluster\n",
    "                predictions[prediction_index].translation = deepcopy(translation.detach().cpu().numpy())\n",
    "                predictions[prediction_index].rotation = deepcopy(rotation_matrix.detach().cpu().numpy())\n",
    "\n",
    "        mapping_result_str = f'Dataset \"{dataset}\" -> {len(images)} images with {len(np.unique(cluster_labels))} clusters'\n",
    "        mapping_result_strs.append(mapping_result_str)\n",
    "        print(mapping_result_str)\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        mapping_result_str = f'Dataset \"{dataset}\" -> Failed!'\n",
    "        mapping_result_strs.append(mapping_result_str)\n",
    "        print(mapping_result_str)\n",
    "\n",
    "# Print summary of results\n",
    "print(\"\\nResults\")\n",
    "for s in mapping_result_strs:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f6ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission file.\n",
    "utils.submission.create_submission_file(samples, OUTPUT_FILE)\n",
    "\n",
    "!head {OUTPUT_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40768d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score, dataset_scores = utils.metric.score(\n",
    "    gt_csv=os.path.join(DATA_DIR, \"train_labels.csv\"),\n",
    "    user_csv=OUTPUT_FILE,\n",
    "    thresholds_csv=os.path.join(DATA_DIR, \"train_thresholds.csv\"),\n",
    "    mask_csv=None,\n",
    "    inl_cf=0,\n",
    "    strict_cf=-1,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
