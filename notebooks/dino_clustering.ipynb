{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5690851",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# DINO Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40763149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from time import sleep, time\n",
    "\n",
    "import kornia as K\n",
    "import numpy as np\n",
    "import pycolmap\n",
    "from IPython.display import clear_output\n",
    "from scripts import utils, database, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79956a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/image-matching-challenge-2025\"\n",
    "DINO_DIR = \"weights/dinov2\"\n",
    "OUTPUT_FILE = \"train_predictions.csv\"\n",
    "\n",
    "DB_IMG_EXT = \"\"\n",
    "DB_CAMERA_MODEL = \"simple-pinhole\"\n",
    "\n",
    "# Configure dataset filtering \n",
    "DATASETS_FILTER = [\n",
    "    # New 2025 datasets\n",
    "    \"amy_gardens\",\n",
    "    \"ETs\",\n",
    "    \"fbk_vineyard\",\n",
    "    \"stairs\",\n",
    "    # Data from IMC 2023 and 2024.\n",
    "    'imc2024_dioscuri_baalshamin',\n",
    "    'imc2023_theather_imc2024_church',\n",
    "    'imc2023_heritage',\n",
    "    'imc2023_haiper',\n",
    "    'imc2024_lizard_pond',\n",
    "    # Crowdsourced PhotoTourism data.\n",
    "    'pt_stpeters_stpauls',\n",
    "    'pt_brandenburg_british_buckingham',\n",
    "    'pt_piazzasanmarco_grandplace',\n",
    "    'pt_sacrecoeur_trevi_tajmahal',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to select an accelerator on the sidebar to the right.\n",
    "device = K.utils.get_cuda_device_if_available(0)\n",
    "print(f\"{device=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23198011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "samples = utils.dataset.load_dataset(DATA_DIR)\n",
    "\n",
    "for dataset in samples:\n",
    "    print(f'Dataset \"{dataset}\" -> num_images={len(samples[dataset])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory to prevent OOM errors\n",
    "gc.collect()\n",
    "mapping_result_strs = []  # Store results for each dataset\n",
    "\n",
    "print(f\"Extracting on device {device}\")\n",
    "# Process each dataset\n",
    "for dataset, predictions in samples.items():\n",
    "    # Skip datasets not in filter list\n",
    "    if DATASETS_FILTER and dataset not in DATASETS_FILTER:\n",
    "        print(f'Skipping \"{dataset}\"')\n",
    "        continue\n",
    "\n",
    "    # Setup paths and image lists\n",
    "    images_dir = os.path.join(DATA_DIR, \"train\", dataset)\n",
    "    images = [os.path.join(images_dir, p.filename) for p in predictions]\n",
    "\n",
    "    print(f'\\nProcessing dataset \"{dataset}\": {len(images)} images')\n",
    "\n",
    "    # Map filenames to prediction indices\n",
    "    filename_to_index = {p.filename: idx for idx, p in enumerate(predictions)}\n",
    "\n",
    "    # Setup output directory for features\n",
    "    feature_dir = os.path.join(\"featureout\", dataset)\n",
    "    os.makedirs(feature_dir, exist_ok=True)\n",
    "\n",
    "    # Wrap algos in try-except blocks so we can populate a submission even if one scene crashes.\n",
    "    try:\n",
    "        # 1. Image pair selection using DINO features\n",
    "        t = time()\n",
    "        cls_descriptor_dino = features.extraction.extract_cls_descriptor_dino(\n",
    "            images,\n",
    "            dino_path=DINO_DIR,\n",
    "            device=device,\n",
    "            normalize=True\n",
    "        )\n",
    "        reduced_features = features.extraction.feature_reducer(\n",
    "            algorithm=\"PCA\",\n",
    "            features=cls_descriptor_dino.cpu().numpy(),\n",
    "            n_components=50,\n",
    "            scaler=None,\n",
    "            random_state=42\n",
    "        )\n",
    "        cluster_labels = features.clustering.dino_clusterer(\n",
    "            algorithm=\"HDBSCAN\",\n",
    "            features=reduced_features,\n",
    "            scaler=None,\n",
    "            min_cluster_size=10,\n",
    "            metric='euclidean',\n",
    "            cluster_selection_method='eom',\n",
    "        )\n",
    "        print(\n",
    "            f\"Clustering. Number of clusters: {np.unique(cluster_labels)}, with {sum(cluster_labels == -1)} outliers. Done in {time() - t:.4f} sec\"\n",
    "        )\n",
    "        gc.collect()\n",
    "        images_np = np.array(images)[cluster_labels != -1]\n",
    "        cluster_labels = cluster_labels[cluster_labels != -1]\n",
    "        for cluster in np.unique(cluster_labels):\n",
    "            cluster_images = images_np[cluster_labels == cluster]\n",
    "            feature_dir_cluster = os.path.join(feature_dir, f\"cluster_{cluster}\")\n",
    "            os.makedirs(feature_dir_cluster, exist_ok=True)\n",
    "\n",
    "            print(f\"Processing Cluster {cluster}: {len(cluster_images)} images\")\n",
    "\n",
    "            index_pairs = features.matching.get_image_pairs_shortlist_dino(\n",
    "                cluster_images.tolist(),\n",
    "                dino_path=DINO_DIR,\n",
    "                sim_th=0.3,  # Strict similarity threshold\n",
    "                min_pairs=20,  # Minimum pairs per image with biggest similarity\n",
    "                exhaustive_if_less=20,\n",
    "                device=device,\n",
    "            )\n",
    "            print(\n",
    "                f\"Shortlisting. Number of pairs to match: {len(index_pairs)}. Done in {time() - t:.4f} sec\"\n",
    "            )\n",
    "            gc.collect()\n",
    "\n",
    "            # 2. Local feature detection with ALIKED\n",
    "            t = time()\n",
    "            features.extraction.detect_keypoint_aliked(images, feature_dir_cluster, 4096, device=device)\n",
    "            gc.collect()\n",
    "            print(f\"Features detected in {time() - t:.4f} sec\")\n",
    "\n",
    "            # 3. Feature matching with LightGlue\n",
    "            t = time()\n",
    "            features.matching.match_keypoint_lightglue(\n",
    "                images, index_pairs, feature_dir=feature_dir_cluster, device=device, verbose=False\n",
    "            )\n",
    "            print(f\"Features matched in {time() - t:.4f} sec\")\n",
    "\n",
    "            # 4. Create/reset COLMAP database\n",
    "            database_path = os.path.join(feature_dir_cluster, \"colmap.db\")\n",
    "            if os.path.isfile(database_path):\n",
    "                os.remove(database_path)\n",
    "            gc.collect()\n",
    "            sleep(1)\n",
    "            # Import features and matches into COLMAP format\n",
    "            database.h5_to_db.import_into_colmap(\n",
    "                images_dir,\n",
    "                DB_CAMERA_MODEL,\n",
    "                img_ext=DB_IMG_EXT,\n",
    "                feature_dir=feature_dir_cluster,\n",
    "                database_path=database_path,\n",
    "            )\n",
    "            output_path = f\"{feature_dir_cluster}/colmap_rec_aliked\"\n",
    "\n",
    "            # 5. Geometric verification with RANSAC\n",
    "            t = time()\n",
    "            pycolmap.match_exhaustive(database_path)\n",
    "            print(f\"Ran RANSAC in {time() - t:.4f} sec\")\n",
    "\n",
    "            # 6. SfM reconstruction with COLMAP\n",
    "            # Configure reconstruction parameters\n",
    "            mapper_options = pycolmap.IncrementalPipelineOptions()\n",
    "            mapper_options.min_model_size = 3  # Allow small reconstructions (min 3 images). Colmap by default does not generate a reconstruction if <10 images are registered.\n",
    "            mapper_options.max_num_models = 25  # Limit number of separate models\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "            t = time()\n",
    "            maps = pycolmap.incremental_mapping(\n",
    "                database_path=database_path,\n",
    "                image_path=images_dir,\n",
    "                output_path=output_path,\n",
    "                options=mapper_options,\n",
    "            )\n",
    "            sleep(1)\n",
    "            print(f\"Reconstruction done in  {time() - t:.4f} sec\")\n",
    "            print(maps)\n",
    "\n",
    "            clear_output(wait=False)\n",
    "\n",
    "            # 7. Extract poses from reconstruction\n",
    "            registered = 0\n",
    "            for map_index, cur_map in maps.items():\n",
    "                for _, image in cur_map.images.items():\n",
    "                    prediction_index = filename_to_index[image.name]\n",
    "                    # predictions[prediction_index].cluster_index = map_index\n",
    "                    predictions[prediction_index].cluster_index = cluster\n",
    "                    predictions[prediction_index].rotation = deepcopy(\n",
    "                        image.cam_from_world.rotation.matrix()\n",
    "                    )\n",
    "                    predictions[prediction_index].translation = deepcopy(\n",
    "                        image.cam_from_world.translation\n",
    "                    )\n",
    "                    registered += 1\n",
    "            mapping_result_str = f'Dataset \"{dataset}\" -> Registered {registered} / {len(images)} images with {len(np.unique(cluster_labels))} clusters'\n",
    "            mapping_result_strs.append(mapping_result_str)\n",
    "            print(mapping_result_str)\n",
    "            print(f\"# clusters predicted by colmap: {len(maps)}\")\n",
    "            gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # raise e\n",
    "        mapping_result_str = f'Dataset \"{dataset}\" -> Failed!'\n",
    "        mapping_result_strs.append(mapping_result_str)\n",
    "        print(mapping_result_str)\n",
    "\n",
    "# Print summary of results\n",
    "print(\"\\nResults\")\n",
    "for s in mapping_result_strs:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f1bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission file.\n",
    "utils.submission.create_submission_file(samples, OUTPUT_FILE)\n",
    "\n",
    "!head {OUTPUT_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b627dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute results if running on the training set.\n",
    "# Don't do this when submitting a notebook for scoring. All you have to do is save your submission to /kaggle/working/submission.csv.\n",
    "\n",
    "t = time()\n",
    "final_score, dataset_scores = utils.metric.score(\n",
    "    gt_csv=os.path.join(DATA_DIR, \"train_labels.csv\"),\n",
    "    user_csv=OUTPUT_FILE,\n",
    "    thresholds_csv=os.path.join(DATA_DIR, \"train_thresholds.csv\"),\n",
    "    mask_csv=None,\n",
    "    inl_cf=0,\n",
    "    strict_cf=-1,\n",
    "    verbose=True,\n",
    ")\n",
    "print(f\"Computed metric in: {time() - t:.02f} sec.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
